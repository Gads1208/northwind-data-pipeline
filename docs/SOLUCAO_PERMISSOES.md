## ğŸ”§ SOLUÃ‡ÃƒO: Configurar PermissÃµes no BigQuery

### ğŸ¯ Problema Identificado

A Service Account estÃ¡ autenticada âœ…, mas:
- âŒ NÃ£o consegue listar datasets
- âŒ NÃ£o consegue criar tabelas
- âŒ Datasets podem nÃ£o existir OU faltam permissÃµes

---

## âœ… SOLUÃ‡ÃƒO RÃPIDA (5 minutos)

### **Passo 1: Dar PermissÃµes Ã  Service Account** (FAÃ‡A PRIMEIRO)

1. **Abra o IAM do projeto:**
   ```
   https://console.cloud.google.com/iam-admin/iam?project=portifolio-482811
   ```

2. **Encontre sua Service Account**
   - Procure por um email terminando em `@portifolio-482811.iam.gserviceaccount.com`
   - Exemplo: `data-pipeline@portifolio-482811.iam.gserviceaccount.com`

3. **Editar PermissÃµes**
   - Clique no Ã­cone de **lÃ¡pis (âœï¸)** ao lado da Service Account
   - Clique em **"+ ADD ANOTHER ROLE"**
   - Procure e selecione: **BigQuery Admin**
   - Clique em **SAVE**

   > âš¡ **BigQuery Admin** dÃ¡ permissÃµes completas (ideal para desenvolvimento)

---

### **Passo 2: Criar os 3 Datasets**

1. **Abra o BigQuery Console:**
   ```
   https://console.cloud.google.com/bigquery?project=portifolio-482811
   ```

2. **Criar Dataset Bronze:**
   - No painel esquerdo, clique nos **3 pontinhos (â‹®)** ao lado do projeto `portifolio-482811`
   - Selecione **"Create dataset"**
   - Preencha:
     ```
     Dataset ID: northwind_bronze
     Data location: US (multiple regions in United States)
     Default table expiration: Never
     ```
   - Clique em **CREATE DATASET**

3. **Criar Dataset Silver:**
   - Repita o processo acima com:
     ```
     Dataset ID: northwind_silver
     Data location: US
     ```

4. **Criar Dataset Gold:**
   - Repita o processo acima com:
     ```
     Dataset ID: northwind_gold
     Data location: US
     ```

---

### **Passo 3: Testar Novamente**

Depois de criar os datasets e dar permissÃµes, execute:

```bash
# 1. Verificar se agora consegue listar datasets
docker exec airflow-webserver python /tmp/check_bigquery.py

# 2. Executar a ingestÃ£o
docker exec airflow-webserver bash -c "cd /opt/airflow/scripts && python postgres_to_bigquery.py"
```

**SaÃ­da esperada:**
```
âœ… ExtraÃ­dos 5 registros da tabela customers
âœ… Carregados 5 registros na tabela bronze_customers
...
==================================================
Total de tabelas: 8
Sucesso: 8
Falhas: 0
Total de registros: 51
==================================================
```

---

## ğŸ¬ VISUAL GUIDE - Passo a Passo com Screenshots

### 1ï¸âƒ£ Conceder PermissÃµes (IAM)

```
1. VÃ¡ em: Cloud Console â†’ IAM & Admin â†’ IAM
   https://console.cloud.google.com/iam-admin/iam?project=portifolio-482811

2. VocÃª verÃ¡ uma lista de principals (usuÃ¡rios/service accounts)

3. Encontre sua Service Account (algo como):
   ğŸ“§ xxxxx@portifolio-482811.iam.gserviceaccount.com
   
4. Clique no Ã­cone âœï¸ (Edit principal) Ã  direita

5. Na seÃ§Ã£o "Assign roles", clique em "+ ADD ANOTHER ROLE"

6. No campo de busca, digite: "BigQuery Admin"

7. Selecione: BigQuery Admin

8. Clique em SAVE
```

### 2ï¸âƒ£ Criar Datasets (BigQuery)

```
1. VÃ¡ em: Cloud Console â†’ BigQuery
   https://console.cloud.google.com/bigquery?project=portifolio-482811

2. No painel EXPLORER (esquerda), vocÃª verÃ¡:
   ğŸ“ portifolio-482811
   
3. Clique nos 3 pontinhos (â‹®) ao lado do nome do projeto

4. Selecione "Create dataset"

5. Preencha o formulÃ¡rio:
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Dataset ID: northwind_bronze        â”‚
   â”‚ Data location: US                   â”‚
   â”‚ Default table expiration: Never     â”‚
   â”‚ Encryption: Google-managed key      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

6. Clique em "CREATE DATASET"

7. Repita para northwind_silver e northwind_gold
```

---

## ğŸ” VerificaÃ§Ã£o Detalhada

Depois de configurar, verifique se tudo estÃ¡ OK:

```bash
# Executar diagnÃ³stico completo
docker exec airflow-webserver python /tmp/check_bigquery.py
```

**SaÃ­da esperada:**
```
âœ… AutenticaÃ§Ã£o OK
ğŸ“ Projeto: portifolio-482811

ğŸ“Š DATASETS EXISTENTES:
  âœ“ northwind_bronze
    Location: US
    Tables: 0
  âœ“ northwind_silver
    Location: US
    Tables: 0
  âœ“ northwind_gold
    Location: US
    Tables: 0

ğŸ¯ DATASETS NECESSÃRIOS:
  âœ… northwind_bronze existe
  âœ… northwind_silver existe
  âœ… northwind_gold existe
```

---

## ğŸš€ Depois que Funcionar

### 1. Testar IngestÃ£o Completa

```bash
docker exec airflow-webserver bash -c "cd /opt/airflow/scripts && python postgres_to_bigquery.py"
```

### 2. Verificar Dados no BigQuery

```bash
docker exec airflow-webserver python -c "
from google.cloud import bigquery
from google.oauth2 import service_account

credentials = service_account.Credentials.from_service_account_file(
    '/opt/airflow/gcp-key.json'
)
client = bigquery.Client(credentials=credentials, project='portifolio-482811')

# Listar tabelas criadas
for dataset_id in ['northwind_bronze', 'northwind_silver', 'northwind_gold']:
    tables = list(client.list_tables(f'portifolio-482811.{dataset_id}'))
    print(f'\n{dataset_id}: {len(tables)} tabelas')
    for table in tables:
        query = f'SELECT COUNT(*) as count FROM \`portifolio-482811.{dataset_id}.{table.table_id}\`'
        result = list(client.query(query))[0]
        print(f'  - {table.table_id}: {result.count} registros')
"
```

### 3. Executar DAG no Airflow

```
http://localhost:8080
Username: airflow
Password: airflow

â†’ DAGs â†’ northwind_data_pipeline â†’ Trigger DAG â–¶ï¸
```

---

## â“ Troubleshooting

### Erro: "Service Account nÃ£o aparece no IAM"

Verifique qual Service Account estÃ¡ sendo usada:

```bash
docker exec airflow-webserver python -c "
import json
with open('/opt/airflow/gcp-key.json') as f:
    key = json.load(f)
    print('Service Account Email:', key['client_email'])
"
```

Se a Service Account nÃ£o aparecer na lista do IAM:

1. VÃ¡ em: **IAM & Admin â†’ Service Accounts**
2. Encontre a Service Account
3. Clique nos **3 pontinhos (â‹®)** â†’ **Manage permissions**
4. Grant Access â†’ Add: **BigQuery Admin**

### Erro: "Ainda sem permissÃ£o apÃ³s adicionar role"

Aguarde 1-2 minutos para as permissÃµes propagarem, depois:

```bash
# Reiniciar container (para renovar credenciais)
docker-compose restart airflow-webserver airflow-scheduler

# Testar novamente
docker exec airflow-webserver python /tmp/check_bigquery.py
```

---

## ğŸ“š ReferÃªncias

- [BigQuery Roles](https://cloud.google.com/bigquery/docs/access-control)
- [Service Account Permissions](https://cloud.google.com/iam/docs/service-accounts)
- [BigQuery Datasets](https://cloud.google.com/bigquery/docs/datasets-intro)

---

**PrÃ³ximo passo**: Depois que funcionar, volte ao [TESTE_PIPELINE.md](TESTE_PIPELINE.md) para executar o pipeline completo!
