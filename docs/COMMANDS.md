# âš¡ Guia de Comandos RÃ¡pidos

ReferÃªncia rÃ¡pida de comandos para gerenciar o projeto Northwind Data Pipeline.

---

## ðŸš€ InÃ­cio RÃ¡pido

```bash
# Setup completo em um comando
./setup.sh

# Ou manualmente:
cp .env.example .env          # Copiar configuraÃ§Ãµes
docker-compose up -d          # Iniciar containers
make check-health             # Verificar saÃºde
```

---

## ðŸ³ Gerenciamento de Containers

### Iniciar/Parar

```bash
# Iniciar todos os serviÃ§os
make up
# ou
docker-compose up -d

# Parar todos os serviÃ§os
make down
# ou
docker-compose down

# Reiniciar serviÃ§os
make restart
# ou
docker-compose restart

# Ver status dos containers
make ps
# ou
docker-compose ps
```

### Logs

```bash
# Ver logs de todos os serviÃ§os
make logs
# ou
docker-compose logs -f

# Logs especÃ­ficos
make logs-airflow        # Airflow apenas
make logs-airbyte        # Airbyte apenas
make logs-postgres       # PostgreSQL apenas

# Logs de um container especÃ­fico
docker-compose logs -f [nome-do-container]
```

### Shell nos Containers

```bash
# Airflow
make shell-airflow
# ou
docker exec -it airflow-webserver bash

# PostgreSQL
make shell-postgres
# ou
docker exec -it northwind-postgres psql -U postgres -d northwind

# Qualquer container
docker exec -it [nome-do-container] bash
```

---

## ðŸ’¾ PostgreSQL

### Conectar ao Banco

```bash
# Via container
docker exec -it northwind-postgres psql -U postgres -d northwind

# Via cliente local (se tiver psql instalado)
psql -h localhost -p 5432 -U postgres -d northwind
```

### Comandos SQL Ãšteis

```sql
-- Listar tabelas
\dt

-- Descrever tabela
\d customers

-- Contar registros
SELECT COUNT(*) FROM customers;
SELECT COUNT(*) FROM orders;

-- Ver dados
SELECT * FROM customers LIMIT 5;

-- Sair
\q
```

### Backup e Restore

```bash
# Criar backup
make backup-postgres
# ou
docker exec northwind-postgres pg_dump -U postgres northwind > backup.sql

# Restaurar backup
make restore-postgres FILE=backup.sql
# ou
docker exec -i northwind-postgres psql -U postgres northwind < backup.sql
```

---

## ðŸ”„ dbt

### Comandos BÃ¡sicos

```bash
# Executar todos os modelos
make dbt-run
# ou
docker exec -it airflow-webserver bash -c "cd /opt/airflow/dbt/northwind_dw && dbt run --profiles-dir /opt/airflow/dbt"

# Executar testes
make dbt-test
# ou
docker exec -it airflow-webserver bash -c "cd /opt/airflow/dbt/northwind_dw && dbt test --profiles-dir /opt/airflow/dbt"

# Gerar documentaÃ§Ã£o
make dbt-docs
# ou
docker exec -it airflow-webserver bash -c "cd /opt/airflow/dbt/northwind_dw && dbt docs generate --profiles-dir /opt/airflow/dbt"
```

### Por Camada

```bash
# Bronze apenas
make dbt-bronze
# ou
docker exec -it airflow-webserver bash -c "cd /opt/airflow/dbt/northwind_dw && dbt run --select tag:bronze --profiles-dir /opt/airflow/dbt"

# Silver apenas
make dbt-silver

# Gold apenas
make dbt-gold
```

### Comandos AvanÃ§ados

```bash
# Dentro do container do Airflow
docker exec -it airflow-webserver bash
cd /opt/airflow/dbt/northwind_dw

# Executar modelo especÃ­fico
dbt run --select bronze_customers --profiles-dir /opt/airflow/dbt

# Executar modelo e dependÃªncias
dbt run --select +silver_dim_customers --profiles-dir /opt/airflow/dbt

# Executar modelo e downstream
dbt run --select silver_dim_customers+ --profiles-dir /opt/airflow/dbt

# Debug (testar conexÃ£o)
dbt debug --profiles-dir /opt/airflow/dbt

# Compilar sem executar
dbt compile --profiles-dir /opt/airflow/dbt

# Ver lineage
dbt docs serve --profiles-dir /opt/airflow/dbt --port 8081
```

---

## âœˆï¸ Apache Airflow

### Acessar

```
URL: http://localhost:8080
UsuÃ¡rio: airflow
Senha: airflow
```

### Comandos CLI

```bash
# Listar DAGs
docker exec -it airflow-scheduler airflow dags list

# Ver informaÃ§Ãµes de um DAG
docker exec -it airflow-scheduler airflow dags show northwind_data_pipeline

# Trigger manual de um DAG
docker exec -it airflow-scheduler airflow dags trigger northwind_data_pipeline

# Pausar/Despausar DAG
docker exec -it airflow-scheduler airflow dags pause northwind_data_pipeline
docker exec -it airflow-scheduler airflow dags unpause northwind_data_pipeline

# Ver tasks de um DAG
docker exec -it airflow-scheduler airflow tasks list northwind_data_pipeline

# Testar uma task especÃ­fica
docker exec -it airflow-scheduler airflow tasks test northwind_data_pipeline dbt_run_bronze 2024-01-01

# Ver logs de uma task
docker exec -it airflow-scheduler airflow tasks logs northwind_data_pipeline dbt_run_bronze 2024-01-01
```

---

## ðŸ”Œ Airbyte

### Acessar

```
URL: http://localhost:8000
(First time: create account)
```

### Via API (avanÃ§ado)

```bash
# Health check
curl http://localhost:8000/api/v1/health

# Listar connections (requer autenticaÃ§Ã£o)
curl -X POST http://localhost:8000/api/v1/connections/list \
  -H "Content-Type: application/json" \
  -d '{"workspaceId": "your-workspace-id"}'
```

---

## â˜ï¸ Google BigQuery

### Via CLI (gcloud)

```bash
# Listar datasets
bq ls

# Listar tabelas em um dataset
bq ls northwind_bronze
bq ls northwind_silver
bq ls northwind_gold

# Ver schema de uma tabela
bq show northwind_bronze.bronze_customers

# Executar query
bq query --use_legacy_sql=false 'SELECT COUNT(*) FROM `project-id.northwind_bronze.bronze_customers`'

# Copiar tabela
bq cp northwind_silver.silver_dim_customers northwind_backup.customers_backup

# Deletar tabela
bq rm -t northwind_backup.customers_backup
```

### Queries Ãšteis

```bash
# Contar registros em todas as camadas
bq query --use_legacy_sql=false '
SELECT 
  "Bronze" as layer, COUNT(*) as records 
FROM `project-id.northwind_bronze.bronze_orders`
UNION ALL
SELECT 
  "Silver" as layer, COUNT(*) as records 
FROM `project-id.northwind_silver.silver_fact_orders`
UNION ALL
SELECT 
  "Gold" as layer, COUNT(*) as records 
FROM `project-id.northwind_gold.gold_sales_by_country`
'

# Ver queries recentes
bq ls -j -a -n 10
```

---

## ðŸ§¹ ManutenÃ§Ã£o

### Limpeza

```bash
# Limpar containers parados
docker container prune

# Limpar imagens nÃ£o usadas
docker image prune -a

# Limpar volumes nÃ£o usados
docker volume prune

# Limpar tudo (CUIDADO!)
make clean
# ou
docker system prune -a --volumes
```

### AtualizaÃ§Ã£o

```bash
# Atualizar imagens Docker
docker-compose pull

# Recriar containers
docker-compose up -d --force-recreate

# Atualizar dependÃªncias dbt
docker exec -it airflow-webserver bash -c "cd /opt/airflow/dbt/northwind_dw && dbt deps --profiles-dir /opt/airflow/dbt"
```

### VerificaÃ§Ã£o de SaÃºde

```bash
# Check completo
make check-health

# Manualmente
curl -s http://localhost:8080/health | jq              # Airflow
curl -s http://localhost:8000/api/v1/health | jq       # Airbyte
docker exec northwind-postgres pg_isready -U postgres   # PostgreSQL
```

---

## ðŸ” Troubleshooting

### Containers nÃ£o iniciam

```bash
# Ver logs de erro
docker-compose logs

# Parar tudo e reiniciar
docker-compose down
docker-compose up -d

# Remover e recriar (CUIDADO: perde dados)
docker-compose down -v
docker-compose up -d
```

### Sem espaÃ§o em disco

```bash
# Ver uso de disco do Docker
docker system df

# Limpar cache do Docker
docker builder prune

# Limpar tudo nÃ£o usado
docker system prune -a --volumes
```

### Porta jÃ¡ em uso

```bash
# Ver o que estÃ¡ usando a porta
sudo lsof -i :8080  # Airflow
sudo lsof -i :8000  # Airbyte
sudo lsof -i :5432  # PostgreSQL

# Matar processo
sudo kill -9 [PID]

# Ou alterar porta no docker-compose.yml
```

### dbt nÃ£o conecta ao BigQuery

```bash
# Verificar arquivo de credenciais
ls -la gcp-key.json

# Verificar variÃ¡veis de ambiente
docker exec -it airflow-webserver env | grep GCP

# Testar conexÃ£o
docker exec -it airflow-webserver bash -c "cd /opt/airflow/dbt/northwind_dw && dbt debug --profiles-dir /opt/airflow/dbt"
```

### Airbyte sync falha

```bash
# Ver logs do worker
docker-compose logs airbyte-worker

# Testar conectividade Postgres
docker exec -it airbyte-worker ping postgres

# Reiniciar Airbyte
docker-compose restart airbyte-server airbyte-worker
```

---

## ðŸ“Š Monitoramento

### MÃ©tricas do Sistema

```bash
# Ver uso de recursos
docker stats

# Ver apenas containers do projeto
docker stats $(docker-compose ps -q)

# Disco usado pelos volumes
docker system df -v
```

### Logs Importantes

```bash
# Logs de erro apenas
docker-compose logs | grep -i error

# Ãšltimas 100 linhas
docker-compose logs --tail=100

# Desde um horÃ¡rio especÃ­fico
docker-compose logs --since 2024-01-01T00:00:00
```

---

## ðŸŽ¯ Workflows Comuns

### Desenvolvimento de novo modelo dbt

```bash
# 1. Criar arquivo SQL
nano dbt/northwind_dw/models/gold/gold_new_metric.sql

# 2. Testar compilaÃ§Ã£o
docker exec -it airflow-webserver bash -c "cd /opt/airflow/dbt/northwind_dw && dbt compile --select gold_new_metric --profiles-dir /opt/airflow/dbt"

# 3. Executar modelo
docker exec -it airflow-webserver bash -c "cd /opt/airflow/dbt/northwind_dw && dbt run --select gold_new_metric --profiles-dir /opt/airflow/dbt"

# 4. Ver resultado no BigQuery
bq query --use_legacy_sql=false 'SELECT * FROM `project-id.northwind_gold.gold_new_metric` LIMIT 10'
```

### Deploy para produÃ§Ã£o

```bash
# 1. Testar tudo localmente
make dbt-test

# 2. Commit changes
git add .
git commit -m "Add new feature"
git push origin main

# 3. Em produÃ§Ã£o (se tiver CD automÃ¡tico)
# Apenas push para main

# 4. Ou manualmente em prod
ssh prod-server
cd northwind-data-pipeline
git pull
docker-compose up -d
```

### Reprocessar dados

```bash
# 1. Truncar tabelas (se necessÃ¡rio)
# No BigQuery: TRUNCATE TABLE northwind_silver.silver_dim_customers

# 2. Reexecutar dbt
make dbt-run

# 3. Verificar resultados
bq query --use_legacy_sql=false 'SELECT COUNT(*) FROM `project-id.northwind_silver.silver_dim_customers`'
```

---

## ðŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o

- Ver README completo: `cat README.md`
- Ver arquitetura: `cat docs/ARCHITECTURE.md`
- Ver setup: `cat docs/SETUP.md`
- Ver dicionÃ¡rio: `cat docs/DATA_DICTIONARY.md`

### Atalhos Ãšteis

```bash
# Adicionar ao seu .bashrc ou .zshrc

alias nw='cd ~/northwind-data-pipeline'
alias nw-up='cd ~/northwind-data-pipeline && make up'
alias nw-down='cd ~/northwind-data-pipeline && make down'
alias nw-logs='cd ~/northwind-data-pipeline && make logs'
alias nw-dbt='docker exec -it airflow-webserver bash -c "cd /opt/airflow/dbt/northwind_dw && dbt"'
```

### Ferramentas de Desenvolvimento

```bash
# Instalar dbt localmente (opcional)
pip install dbt-bigquery

# Instalar Google Cloud SDK
curl https://sdk.cloud.google.com | bash

# Instalar clientes PostgreSQL
sudo apt-get install postgresql-client  # Linux
brew install postgresql                  # macOS
```

---

**ðŸ’¡ Dica**: Use `make help` para ver todos os comandos disponÃ­veis!

**ðŸ“– Para mais detalhes, consulte**: 
- [README.md](../README.md)
- [docs/SETUP.md](SETUP.md)
- [docs/ARCHITECTURE.md](ARCHITECTURE.md)

---

**Ãšltima atualizaÃ§Ã£o**: 29/12/2024
