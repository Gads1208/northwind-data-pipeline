# Pipeline de Dados Northwind - Arquitetura Medallion

## üéØ Objetivo do Projeto

Desenvolvimento de um pipeline de dados end-to-end implementando a arquitetura Medallion (Bronze, Silver, Gold) com stack moderna de tecnologias em nuvem. O projeto demonstra expertise em ETL/ELT, orquestra√ß√£o de dados, transforma√ß√µes SQL e infraestrutura cloud.

---

## üíº Tecnologias Utilizadas

**Data Engineering:**
- **Python 3.11** - Script ETL customizado (431 linhas)
- **PostgreSQL 15** - Banco de dados fonte (Northwind database)
- **Google BigQuery** - Data Warehouse cloud com 3 datasets
- **dbt 1.7.4** - Transforma√ß√µes de dados e testes de qualidade
- **Apache Airflow 2.8.0** - Orquestra√ß√£o e automa√ß√£o do pipeline

**DevOps & Infraestrutura:**
- **Docker Compose** - Orquestra√ß√£o de 4 containers
- **Git/GitHub** - Versionamento e documenta√ß√£o
- **GCP Service Account** - Autentica√ß√£o e seguran√ßa

---

## üèóÔ∏è Arquitetura Implementada

### Pipeline de Dados (ELT)

```
PostgreSQL (51 registros)
    ‚Üì
Python ETL Script
    ‚Üì
BigQuery Bronze Layer (8 tabelas)
    ‚Üì
dbt Silver Layer (4 modelos dimensionais)
    ‚Üì
dbt Gold Layer (5 agrega√ß√µes de neg√≥cio)
```

### Arquitetura Medallion

**ü•â Bronze Layer (Raw Data)**
- 8 tabelas com dados brutos
- Ingest√£o via Python customizado
- Preserva√ß√£o de dados hist√≥ricos

**ü•à Silver Layer (Modeled Data)**
- 4 modelos dimensionais (star schema)
- Limpeza e padroniza√ß√£o de dados
- Implementa√ß√£o de surrogate keys

**ü•á Gold Layer (Business Metrics)**
- 5 agrega√ß√µes de neg√≥cio
- M√©tricas prontas para an√°lise
- Otimiza√ß√£o para dashboards

---

## üìä Resultados Alcan√ßados

### M√©tricas do Pipeline

| M√©trica | Valor |
|---------|-------|
| **Registros Processados** | 51 registros |
| **Tabelas Bronze** | 8 tabelas |
| **Modelos Silver** | 4 dimens√µes/fatos |
| **Agrega√ß√µes Gold** | 5 m√©tricas |
| **Testes de Qualidade** | 16 testes automatizados |
| **Tempo de Execu√ß√£o** | ~2-3 minutos |

### Principais Entregas

‚úÖ **Pipeline Automatizado** - Orquestra√ß√£o completa via Airflow  
‚úÖ **Qualidade de Dados** - 16 testes automatizados com dbt  
‚úÖ **Documenta√ß√£o Completa** - README detalhado + diagramas  
‚úÖ **Infrastructure as Code** - Docker Compose configurado  
‚úÖ **Cloud Integration** - BigQuery no Google Cloud Platform  

---

## üõ†Ô∏è Desafios T√©cnicos Superados

### 1. Integra√ß√£o dbt + Airflow
**Problema:** Astronomer Cosmos apresentava erros de configura√ß√£o  
**Solu√ß√£o:** Implementa√ß√£o customizada usando BashOperator com TaskGroups para execu√ß√£o modular dos modelos dbt

### 2. Serializa√ß√£o de Dados
**Problema:** Tipos Decimal e datetime n√£o compat√≠veis com BigQuery JSON  
**Solu√ß√£o:** Implementa√ß√£o de custom encoder Python para convers√£o autom√°tica (Decimal‚Üífloat, datetime‚Üíisoformat)

### 3. Gerenciamento de Depend√™ncias
**Problema:** dbt requer git para instala√ß√£o de pacotes  
**Solu√ß√£o:** Cria√ß√£o de entrypoint.sh para instala√ß√£o autom√°tica de depend√™ncias ao iniciar containers

### 4. Modelagem Dimensional
**Problema:** Dados brutos sem estrutura dimensional  
**Solu√ß√£o:** Implementa√ß√£o de star schema com dimens√µes e fatos na camada Silver

---

## üíª C√≥digo e Implementa√ß√£o

### Python ETL (431 linhas)

```python
# Principais funcionalidades implementadas:
- Conex√£o PostgreSQL com psycopg2
- Extra√ß√£o de 8 tabelas com metadata
- Serializa√ß√£o JSON customizada
- Upload para BigQuery com schema inferido
- Tratamento de erros e logging
- Parametriza√ß√£o via vari√°veis de ambiente
```

### dbt Transformations (17 modelos)

**Silver Layer - Modelagem Dimensional:**
```sql
-- silver_dim_customers.sql
SELECT
  {{ dbt_utils.generate_surrogate_key(['customer_id']) }} as customer_key,
  customer_id,
  company_name,
  contact_name,
  country,
  city
FROM {{ ref('bronze_customers') }}
```

**Gold Layer - M√©tricas de Neg√≥cio:**
```sql
-- gold_customer_revenue.sql
SELECT
  customer_id,
  SUM(total_amount) as total_revenue,
  COUNT(order_id) as order_count,
  AVG(total_amount) as avg_order_value
FROM {{ ref('silver_fact_orders') }}
GROUP BY customer_id
```

### Airflow DAG (295 linhas)

```python
# Principais componentes:
- TaskGroups para Silver e Gold layers
- Dynamic task generation para modelos dbt
- BashOperator para execu√ß√£o dbt
- Depend√™ncias configuradas (ingest ‚Üí silver ‚Üí gold ‚Üí tests)
- Schedule configur√°vel (daily/manual)
```

---

## üìà Impacto e Aprendizados

### Skills T√©cnicas Demonstradas

‚úÖ **Python Development** - ETL script robusto com tratamento de erros  
‚úÖ **SQL & Data Modeling** - Star schema e agrega√ß√µes complexas  
‚úÖ **Cloud Engineering** - Google Cloud Platform e BigQuery  
‚úÖ **DevOps** - Docker, containeriza√ß√£o e automa√ß√£o  
‚úÖ **Data Quality** - Testes automatizados e valida√ß√µes  
‚úÖ **Documentation** - README profissional e c√≥digo comentado  

### Boas Pr√°ticas Implementadas

- **Version Control** - Git com commits sem√¢nticos
- **Code Quality** - C√≥digo limpo e modular
- **Testing** - 16 testes de qualidade de dados
- **Documentation** - Documenta√ß√£o completa em Markdown
- **Infrastructure as Code** - Docker Compose para reprodutibilidade
- **Separation of Concerns** - Camadas Bronze/Silver/Gold bem definidas

---

## üîó Links do Projeto

**GitHub Repository:** [github.com/Gads1208/northwind-data-pipeline](https://github.com/Gads1208/northwind-data-pipeline)

**Documenta√ß√£o Completa:** Ver README.md no reposit√≥rio

**Tecnologias:** Python | dbt | Airflow | BigQuery | Docker | PostgreSQL

---

## üéì Conclus√£o

Este projeto demonstra capacidade de:

- Projetar e implementar pipelines de dados escal√°veis
- Trabalhar com tecnologias modernas de Data Engineering
- Resolver problemas t√©cnicos complexos
- Documentar e versionar c√≥digo profissionalmente
- Implementar boas pr√°ticas de engenharia de dados
- Trabalhar com infraestrutura cloud (GCP)

O pipeline est√° **funcional**, **testado** e **pronto para produ√ß√£o**, representando um exemplo real de trabalho em Data Engineering.

---

**Desenvolvido por:** Guilherme Alves da Silva  
**Contato:** gads1208@gmail.com  
**GitHub:** @Gads1208  
**Data:** Dezembro 2025
