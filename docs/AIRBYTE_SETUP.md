# üîå Guia de Instala√ß√£o do Airbyte

O Airbyte requer uma instala√ß√£o separada devido √† sua complexidade. Aqui est√£o as op√ß√µes:

## Op√ß√£o 1: Airbyte Cloud (Recomendado para Produ√ß√£o)

A maneira mais simples √© usar o Airbyte Cloud:

1. Acesse https://cloud.airbyte.com
2. Crie uma conta gratuita
3. Configure source (PostgreSQL) e destination (BigQuery)
4. Sem necessidade de infraestrutura local

**Pr√≥s**: Sem gerenciamento, escal√°vel, sempre atualizado
**Contras**: Requer conta, limites no plano gratuito

## Op√ß√£o 2: Airbyte OSS Local (Para Desenvolvimento)

### Instala√ß√£o via abctl (Recomendado)

```bash
# 1. Baixar abctl
curl -LsfS https://get.airbyte.com | bash -

# 2. Instalar Airbyte
abctl local install

# 3. Acessar
# UI: http://localhost:8000
# Credentials: airbyte / password
```

### Instala√ß√£o via Docker Compose (Manual)

```bash
# 1. Clonar reposit√≥rio do Airbyte
git clone https://github.com/airbytehq/airbyte.git
cd airbyte

# 2. Executar
./run-ab-platform.sh

# 3. Acessar http://localhost:8000
```

## Op√ß√£o 3: Alternativa Simples - Scripts Python

Para um projeto de portf√≥lio, voc√™ pode substituir o Airbyte por scripts Python simples:

```python
# airflow/dags/ingest_postgres_to_bigquery.py
from airflow import DAG
from airflow.providers.google.cloud.transfers.postgres_to_gcs import PostgresToGCSOperator
from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GCSToBigQueryOperator
from datetime import datetime

with DAG(
    'postgres_to_bigquery',
    start_date=datetime(2024, 1, 1),
    schedule_interval='@hourly',
    catchup=False
) as dag:
    
    tables = ['customers', 'orders', 'products', 'employees']
    
    for table in tables:
        # PostgreSQL ‚Üí GCS
        pg_to_gcs = PostgresToGCSOperator(
            task_id=f'extract_{table}',
            postgres_conn_id='postgres_conn',
            sql=f'SELECT * FROM {table}',
            bucket='your-bucket',
            filename=f'bronze/{table}/{{{{ ds }}}}.json',
            export_format='json'
        )
        
        # GCS ‚Üí BigQuery
        gcs_to_bq = GCSToBigQueryOperator(
            task_id=f'load_{table}',
            bucket='your-bucket',
            source_objects=[f'bronze/{table}/{{{{ ds }}}}.json'],
            destination_project_dataset_table=f'northwind_bronze.bronze_{table}',
            write_disposition='WRITE_TRUNCATE',
            source_format='NEWLINE_DELIMITED_JSON'
        )
        
        pg_to_gcs >> gcs_to_bq
```

## Op√ß√£o 4: Usar apenas dbt com Sources Externas

Se os dados j√° est√£o no BigQuery (via load manual), voc√™ pode pular o Airbyte:

```bash
# 1. Fazer upload manual dos CSVs para BigQuery
bq load --source_format=CSV \
    northwind_bronze.bronze_customers \
    customers.csv \
    schema.json

# 2. Usar dbt direto nas tabelas Bronze
```

## Configura√ß√£o Recomendada para Este Projeto

### Para Desenvolvimento/Portf√≥lio:

**Op√ß√£o A - Simples**: 
- Use scripts Python no Airflow (Op√ß√£o 3)
- Ou fa√ßa upload manual inicial e foque nas transforma√ß√µes dbt

**Op√ß√£o B - Completo**:
- Use Airbyte Cloud (gr√°tis) ou `abctl local install`
- Configure uma vez e documente no README

### Para Produ√ß√£o Real:

- Use Airbyte Cloud ou self-hosted em Kubernetes
- Configure monitoring e alertas
- Implemente retry logic robusto

## Configura√ß√£o do Airbyte para este Projeto

### Source: PostgreSQL

```yaml
Host: postgres (ou localhost se Airbyte externo)
Port: 5432
Database: northwind
Username: postgres
Password: postgres
SSL Mode: disable
```

### Destination: BigQuery

```yaml
Project ID: northwind-data-pipeline
Dataset: northwind_bronze
Location: US
Loading Method: Standard Inserts
Service Account Key: (cole o JSON)
```

### Connection Settings

```yaml
Sync Mode: Full Refresh | Overwrite
Schedule: Every hour
Namespace: Custom (northwind_bronze)
Tables: Select all
```

## Verifica√ß√£o

Ap√≥s configurar o Airbyte, verifique se os dados chegaram no BigQuery:

```bash
bq query --use_legacy_sql=false \
  'SELECT COUNT(*) as total FROM `northwind-data-pipeline.northwind_bronze.bronze_customers`'
```

## Troubleshooting

### Problema: Airbyte n√£o conecta ao PostgreSQL

**Solu√ß√£o**: Use o host correto
- Se Airbyte est√° no Docker: `postgres`
- Se Airbyte est√° local: `host.docker.internal` ou `localhost`

### Problema: BigQuery authentication failed

**Solu√ß√£o**: Verifique a service account key
- Deve ter permiss√µes: BigQuery Data Editor e Job User
- JSON deve estar v√°lido

### Problema: Schema n√£o detectado

**Solu√ß√£o**: Verifique tabelas no Postgres
```bash
docker exec -it northwind-postgres psql -U postgres -d northwind -c "\dt"
```

## Recursos

- [Airbyte Documentation](https://docs.airbyte.com/)
- [Airbyte Quickstart](https://docs.airbyte.com/quickstart)
- [PostgreSQL Connector](https://docs.airbyte.com/integrations/sources/postgres)
- [BigQuery Connector](https://docs.airbyte.com/integrations/destinations/bigquery)

---

**Nota**: Para fins de portf√≥lio, voc√™ pode documentar que usaria Airbyte em produ√ß√£o, mas implementar com scripts Python mais simples para demonstra√ß√£o.
