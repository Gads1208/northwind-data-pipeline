# ğŸš€ Northwind Data Pipeline - Projeto de Engenharia de Dados

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![dbt](https://img.shields.io/badge/dbt-1.7-orange)](https://www.getdbt.com/)
[![Airflow](https://img.shields.io/badge/Airflow-2.8-blue)](https://airflow.apache.org/)

Um pipeline completo de engenharia de dados implementando arquitetura Medallion (Bronze, Silver, Gold) com stack moderna de tecnologias.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Arquitetura](#arquitetura)
- [Tecnologias](#tecnologias)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [PrÃ©-requisitos](#prÃ©-requisitos)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)
- [ExecuÃ§Ã£o](#execuÃ§Ã£o)
- [Camadas de Dados](#camadas-de-dados)
- [Monitoramento](#monitoramento)
- [Testes](#testes)

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um pipeline de dados end-to-end utilizando a clÃ¡ssica base de dados **Northwind** como fonte. O objetivo Ã© demonstrar as melhores prÃ¡ticas de engenharia de dados moderna, incluindo:

- **IngestÃ£o de dados** com Airbyte
- **TransformaÃ§Ã£o de dados** com dbt usando arquitetura Medallion
- **OrquestraÃ§Ã£o** com Apache Airflow
- **Armazenamento** no Google BigQuery
- **Versionamento** com Git/GitHub

### Fluxo de Dados

```
PostgreSQL (Source) 
    â†“
Airbyte (Ingestion)
    â†“
BigQuery Bronze (Raw Data)
    â†“
dbt Silver (Cleaned & Transformed)
    â†“
dbt Gold (Business Aggregations)
    â†“
Analytics & BI Tools
```

## ğŸ—ï¸ Arquitetura

### Arquitetura Medallion

O projeto implementa a arquitetura Medallion em trÃªs camadas:

#### ğŸ¥‰ Bronze Layer (Dados Brutos)
- Dados brutos ingeridos do PostgreSQL via Airbyte
- MÃ­nima ou nenhuma transformaÃ§Ã£o
- Preserva histÃ³rico completo
- Tabelas: `bronze_customers`, `bronze_orders`, `bronze_products`, etc.

#### ğŸ¥ˆ Silver Layer (Dados Limpos)
- Dados limpos e padronizados
- DeduplicaÃ§Ã£o e validaÃ§Ãµes
- Enriquecimento com dados de referÃªncia
- Tabelas: `silver_dim_customers`, `silver_dim_products`, `silver_fact_orders`

#### ğŸ¥‡ Gold Layer (AgregaÃ§Ãµes de NegÃ³cio)
- MÃ©tricas e KPIs de negÃ³cio
- Dados otimizados para anÃ¡lise
- AgregaÃ§Ãµes e cÃ¡lculos complexos
- Tabelas: `gold_sales_by_country`, `gold_customer_analytics`, `gold_employee_performance`

### Diagrama de Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚     â”‚             â”‚     â”‚                  â”‚
â”‚  PostgreSQL â”‚â”€â”€â”€â”€â–¶â”‚   Airbyte   â”‚â”€â”€â”€â”€â–¶â”‚  BigQuery Bronze â”‚
â”‚  (Source)   â”‚     â”‚  (Ingest)   â”‚     â”‚   (Raw Data)     â”‚
â”‚             â”‚     â”‚             â”‚     â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â”‚
                                                  â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚          dbt Transformations         â”‚
                    â”‚                                      â”‚
                    â”‚  Bronze â†’ Silver â†’ Gold             â”‚
                    â”‚  (Medallion Architecture)           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â”‚
                                    â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    Apache Airflow (Orchestration)   â”‚
              â”‚                                     â”‚
              â”‚  - Pipeline Scheduling              â”‚
              â”‚  - Data Quality Checks              â”‚
              â”‚  - Monitoring & Alerts              â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tecnologias

| Tecnologia | VersÃ£o | FunÃ§Ã£o |
|------------|--------|--------|
| **PostgreSQL** | 15 | Banco de dados fonte |
| **Airbyte** | Latest | IngestÃ£o de dados |
| **Google BigQuery** | - | Data Warehouse |
| **dbt** | 1.7+ | TransformaÃ§Ãµes de dados |
| **Apache Airflow** | 2.8 | OrquestraÃ§Ã£o |
| **Docker** | Latest | ContainerizaÃ§Ã£o |
| **Python** | 3.11 | Linguagem principal |

## ğŸ“ Estrutura do Projeto

```
northwind-data-pipeline/
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ postgres/
â”‚   â””â”€â”€ init/
â”‚       â”œâ”€â”€ 01_schema.sql         # Schema do banco Northwind
â”‚       â””â”€â”€ 02_data.sql           # Dados de exemplo
â”‚
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â”œâ”€â”€ northwind_pipeline_dag.py      # DAG principal do pipeline
â”‚       â”œâ”€â”€ northwind_monitoring_dag.py    # DAG de monitoramento
â”‚       â””â”€â”€ northwind_maintenance_dag.py   # DAG de manutenÃ§Ã£o
â”‚
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ profiles.yml              # ConfiguraÃ§Ã£o de conexÃ£o dbt
â”‚   â””â”€â”€ northwind_dw/
â”‚       â”œâ”€â”€ dbt_project.yml       # ConfiguraÃ§Ã£o do projeto dbt
â”‚       â”œâ”€â”€ packages.yml          # Pacotes dbt
â”‚       â””â”€â”€ models/
â”‚           â”œâ”€â”€ bronze/           # Camada Bronze (Raw)
â”‚           â”‚   â”œâ”€â”€ bronze_customers.sql
â”‚           â”‚   â”œâ”€â”€ bronze_orders.sql
â”‚           â”‚   â”œâ”€â”€ bronze_products.sql
â”‚           â”‚   â””â”€â”€ ...
â”‚           â”œâ”€â”€ silver/           # Camada Silver (Cleaned)
â”‚           â”‚   â”œâ”€â”€ silver_dim_customers.sql
â”‚           â”‚   â”œâ”€â”€ silver_dim_products.sql
â”‚           â”‚   â”œâ”€â”€ silver_fact_orders.sql
â”‚           â”‚   â””â”€â”€ ...
â”‚           â””â”€â”€ gold/             # Camada Gold (Business)
â”‚               â”œâ”€â”€ gold_sales_by_country.sql
â”‚               â”œâ”€â”€ gold_customer_analytics.sql
â”‚               â”œâ”€â”€ gold_employee_performance.sql
â”‚               â””â”€â”€ ...
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ SETUP.md                  # Guia de instalaÃ§Ã£o detalhado
    â”œâ”€â”€ ARCHITECTURE.md           # DocumentaÃ§Ã£o da arquitetura
    â””â”€â”€ DATA_DICTIONARY.md        # DicionÃ¡rio de dados
```

## ğŸ“¦ PrÃ©-requisitos

- **Docker** e **Docker Compose** instalados
- **Google Cloud Platform** account com BigQuery habilitado
- **Service Account Key** do GCP com permissÃµes:
  - BigQuery Data Editor
  - BigQuery Job User
- **Git** para versionamento
- MÃ­nimo de **8GB RAM** e **20GB** de espaÃ§o em disco

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/northwind-data-pipeline.git
cd northwind-data-pipeline
```

### 2. Configure as variÃ¡veis de ambiente

```bash
cp .env.example .env
```

Edite o arquivo `.env` com suas credenciais:

```bash
# Google Cloud Configuration
GCP_PROJECT_ID=seu-project-id
GCP_DATASET_BRONZE=northwind_bronze
GCP_DATASET_SILVER=northwind_silver
GCP_DATASET_GOLD=northwind_gold
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account-key.json

# PostgreSQL Configuration
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=northwind
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
```

### 3. Configure o Google Cloud

```bash
# Crie os datasets no BigQuery
bq mk --dataset ${GCP_PROJECT_ID}:northwind_bronze
bq mk --dataset ${GCP_PROJECT_ID}:northwind_silver
bq mk --dataset ${GCP_PROJECT_ID}:northwind_gold
```

### 4. Inicie os serviÃ§os

```bash
docker-compose up -d
```

Aguarde alguns minutos para todos os serviÃ§os iniciarem.

## âš™ï¸ ConfiguraÃ§Ã£o

### Configurar Airbyte

1. Acesse http://localhost:8000
2. Crie uma **Source** (PostgreSQL):
   - Host: `postgres`
   - Port: `5432`
   - Database: `northwind`
   - Username: `postgres`
   - Password: `postgres`

3. Crie uma **Destination** (BigQuery):
   - Project ID: seu project ID
   - Dataset: `northwind_bronze`
   - Credentials: sua service account key

4. Crie uma **Connection**:
   - Selecione todas as tabelas
   - Sync frequency: Hourly
   - Destination namespace: Custom format â†’ `northwind_bronze`

### Configurar dbt

```bash
# Entre no container do Airflow
docker exec -it airflow-webserver bash

# Instale as dependÃªncias do dbt
cd /opt/airflow/dbt/northwind_dw
dbt deps --profiles-dir /opt/airflow/dbt

# Teste a conexÃ£o
dbt debug --profiles-dir /opt/airflow/dbt
```

### Configurar Airflow

1. Acesse http://localhost:8080
   - Username: `airflow`
   - Password: `airflow`

2. Configure as variÃ¡veis:
   - `gcp_project`: seu project ID
   - `gcp_credentials_path`: caminho para service account key

3. Ative os DAGs:
   - `northwind_data_pipeline`
   - `northwind_monitoring`
   - `northwind_maintenance`

## ğŸ® ExecuÃ§Ã£o

### ExecuÃ§Ã£o Manual

#### 1. Executar ingestÃ£o do Airbyte

Acesse o Airbyte em http://localhost:8000 e execute a sincronizaÃ§Ã£o manualmente.

#### 2. Executar transformaÃ§Ãµes dbt

```bash
# Entre no container
docker exec -it airflow-webserver bash

# Execute as transformaÃ§Ãµes
cd /opt/airflow/dbt/northwind_dw

# Bronze layer
dbt run --select tag:bronze --profiles-dir /opt/airflow/dbt

# Silver layer
dbt run --select tag:silver --profiles-dir /opt/airflow/dbt

# Gold layer
dbt run --select tag:gold --profiles-dir /opt/airflow/dbt

# Execute os testes
dbt test --profiles-dir /opt/airflow/dbt
```

#### 3. Executar DAG do Airflow

No Airflow UI (http://localhost:8080), clique em "Trigger DAG" no DAG `northwind_data_pipeline`.

### ExecuÃ§Ã£o AutomÃ¡tica

O pipeline estÃ¡ configurado para executar automaticamente:
- **Pipeline principal**: Diariamente Ã s 2h da manhÃ£
- **Monitoramento**: A cada 4 horas
- **ManutenÃ§Ã£o**: Semanalmente aos domingos Ã s 3h

## ğŸ“Š Camadas de Dados

### Bronze Layer

Dados brutos ingeridos do PostgreSQL:

- `bronze_categories` - Categorias de produtos
- `bronze_customers` - Clientes
- `bronze_employees` - FuncionÃ¡rios
- `bronze_orders` - Pedidos
- `bronze_order_details` - Detalhes dos pedidos
- `bronze_products` - Produtos
- `bronze_suppliers` - Fornecedores
- `bronze_shippers` - Transportadoras

### Silver Layer

Dados limpos e padronizados:

- `silver_dim_customers` - DimensÃ£o de clientes
- `silver_dim_products` - DimensÃ£o de produtos (com categoria e fornecedor)
- `silver_dim_employees` - DimensÃ£o de funcionÃ¡rios
- `silver_fact_orders` - Fato de pedidos (com mÃ©tricas calculadas)

### Gold Layer

AgregaÃ§Ãµes de negÃ³cio:

- `gold_sales_by_country` - Vendas por paÃ­s
- `gold_sales_by_category` - Vendas por categoria de produto
- `gold_employee_performance` - Performance dos funcionÃ¡rios
- `gold_customer_analytics` - AnÃ¡lise de clientes (segmentaÃ§Ã£o, CLV)
- `gold_product_performance` - Performance dos produtos

## ğŸ“ˆ Monitoramento

### Logs do Airflow

```bash
# Visualizar logs em tempo real
docker logs -f airflow-scheduler
```

### MÃ©tricas do dbt

```bash
# Gerar documentaÃ§Ã£o
cd /opt/airflow/dbt/northwind_dw
dbt docs generate --profiles-dir /opt/airflow/dbt
dbt docs serve --profiles-dir /opt/airflow/dbt --port 8081
```

Acesse a documentaÃ§Ã£o em http://localhost:8081

### Verificar dados no BigQuery

```sql
-- Contar registros em cada camada
SELECT 'Bronze' as layer, COUNT(*) as total FROM `project.northwind_bronze.bronze_orders`
UNION ALL
SELECT 'Silver' as layer, COUNT(*) as total FROM `project.northwind_silver.silver_fact_orders`
UNION ALL
SELECT 'Gold' as layer, COUNT(*) as total FROM `project.northwind_gold.gold_sales_by_country`;
```

## ğŸ§ª Testes

### Testes de Qualidade de Dados (dbt)

```bash
# Executar todos os testes
dbt test --profiles-dir /opt/airflow/dbt

# Executar testes de uma camada especÃ­fica
dbt test --select tag:silver --profiles-dir /opt/airflow/dbt
```

### Testes de DAGs do Airflow

```bash
# Testar DAG
docker exec -it airflow-scheduler airflow dags test northwind_data_pipeline 2024-01-01
```

## ğŸ”§ ManutenÃ§Ã£o

### Limpar dados

```bash
# Parar containers
docker-compose down

# Remover volumes (CUIDADO: isso apaga todos os dados)
docker-compose down -v
```

### Atualizar dependÃªncias

```bash
# Atualizar imagens Docker
docker-compose pull

# Reiniciar serviÃ§os
docker-compose up -d
```

## ğŸ“š Recursos Adicionais

- [DocumentaÃ§Ã£o do dbt](https://docs.getdbt.com/)
- [DocumentaÃ§Ã£o do Airflow](https://airflow.apache.org/docs/)
- [DocumentaÃ§Ã£o do Airbyte](https://docs.airbyte.com/)
- [BigQuery Documentation](https://cloud.google.com/bigquery/docs)

## ğŸ‘¤ Autor

**Seu Nome**
- GitHub: [@seu-usuario](https://github.com/seu-usuario)
- LinkedIn: [Seu Perfil](https://linkedin.com/in/seu-perfil)

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ğŸ™ Agradecimentos

- Base de dados Northwind da Microsoft
- Comunidade dbt, Airflow e Airbyte

---

**â­ Se este projeto foi Ãºtil, considere dar uma estrela!**
